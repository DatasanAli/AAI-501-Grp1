{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "{'0': {'precision': 0.8570861452957523, 'recall': 0.9174220963172804, 'f1-score': 0.8862283642334269, 'support': 7060.0}, '1': {'precision': 0.5959805959805959, 'recall': 0.44329896907216493, 'f1-score': 0.5084244753177652, 'support': 1940.0}, 'accuracy': 0.8152222222222222, 'macro avg': {'precision': 0.7265333706381741, 'recall': 0.6803605326947226, 'f1-score': 0.6973264197755961, 'support': 9000.0}, 'weighted avg': {'precision': 0.8008033935544853, 'recall': 0.8152222222222222, 'f1-score': 0.804790637067162, 'support': 9000.0}}\n",
      "ROC-AUC Score: 0.7682076312023598\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from util.model_eval import predict_and_score\n",
    "\n",
    "# Load the model from the file\n",
    "xgb_model = joblib.load('models/xgboost/xbg_model.joblib')\n",
    "xgb_test_features = joblib.load('models/xgboost/test_features.joblib')\n",
    "xgb_test_targets = joblib.load('models/xgboost/test_targets.joblib')\n",
    "\n",
    "xgb_report, xgb_roc_auc = predict_and_score(xgb_model, xgb_test_features, xgb_test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8008033935544853\n",
      "Recall: 0.8152222222222222\n",
      "F1 Score: 0.804790637067162\n",
      "Support: 9000.0\n",
      "ROC AUC: 0.7682076312023598\n"
     ]
    }
   ],
   "source": [
    "# Example of how to access the values in the report\n",
    "precision = xgb_report['weighted avg']['precision']\n",
    "recall = xgb_report['weighted avg']['recall']\n",
    "f1_score = xgb_report['weighted avg']['f1-score']\n",
    "support = xgb_report['weighted avg']['support']\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1_score}')\n",
    "print(f'Support: {support}')\n",
    "print(f'ROC AUC: {xgb_roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4687\n",
      "           1       0.63      0.35      0.45      1313\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.73      0.65      0.67      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n",
      "ROC-AUC Score: 0.7101196760302312\n"
     ]
    }
   ],
   "source": [
    "nb = joblib.load('models/naive_bayes/naive_bayes_ensemble.joblib')\n",
    "nb_test_features = joblib.load('models/naive_bayes/test_features.joblib')\n",
    "nb_test_targets = joblib.load('models/naive_bayes/test_targets.joblib')\n",
    "\n",
    "predict_and_score(nb, nb_test_features, nb_test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit_card_defaults_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
